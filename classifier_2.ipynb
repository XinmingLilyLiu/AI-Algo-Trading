{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, mean_squared_error\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import AdaBoostClassifier, GradientBoostingClassifier, RandomForestClassifier, ExtraTreesClassifier\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def trainAndValidate(x, y, title, subplot):\n",
    "    x = np.array(x)\n",
    "    y = np.array(y)\n",
    "\n",
    "    # randomize data\n",
    "    n = len(x)\n",
    "    indices = np.random.choice(n, n, replace=False)\n",
    "    x = x[indices]\n",
    "    y = y[indices]\n",
    "    \n",
    "    # split into train, test and validation\n",
    "    train_idx = int(n*.8)\n",
    "    test_idx = int(n*.9)\n",
    "    \n",
    "    x_train = x[:train_idx,:]\n",
    "    y_train = y[:train_idx]\n",
    "    \n",
    "    x_test = x[train_idx:test_idx,:]\n",
    "    y_test = y[train_idx:test_idx]\n",
    "\n",
    "    x_valid = x[test_idx:,:]\n",
    "    y_valid = y[test_idx:]\n",
    "\n",
    "    # build models\n",
    "    models = []\n",
    "#     models.append(RandomForestClassifier(n_estimators=1000, max_depth=None,random_state=0, oob_score=True))\n",
    "#     models.append(MultinomialNB())\n",
    "#     models.append(MLPClassifier(solver='lbfgs', alpha=1e-5,hidden_layer_sizes=(5, 2), random_state=1))\n",
    "#     models.append(SVC(gamma='auto'))\n",
    "#     models.append(GradientBoostingClassifier(n_estimators=100, learning_rate = .5, max_features=2, max_depth = 2, random_state = 0))\n",
    "#     models.append(DummyClassifier(strategy='most_frequent', random_state=None, constant=None))\n",
    "    models.append(('LR' , LogisticRegression()))\n",
    "    models.append(('LDA' , LinearDiscriminantAnalysis()))\n",
    "    models.append(('KNN' , KNeighborsClassifier()))\n",
    "    models.append(('CART' , DecisionTreeClassifier()))\n",
    "    models.append(('NB' , GaussianNB()))\n",
    "    models.append(('SVM' , SVC()))\n",
    "    models.append(('RF' , RandomForestClassifier(n_estimators=50)))\n",
    "    models.append(('XGBoost', XGBClassifier()))\n",
    "\n",
    "    training_errors = []\n",
    "    validation_errors = []\n",
    "    names = []\n",
    "    n_groups = len(models)\n",
    "\n",
    "    # test models\n",
    "    print (\"=== Accuracy ===\")\n",
    "    for name, model in models:\n",
    "        model.fit(x_train,y_train)\n",
    "        y_pred = model.predict(x_test)\n",
    "        train_error = sum(y_test!=y_pred)/len(y_test)\n",
    "        training_errors.append(train_error)\n",
    "\n",
    "        pred_valid = model.predict(x_valid)\n",
    "        valid_error = sum(np.array(y_valid)!=np.array(pred_valid))/len(y_valid)\n",
    "        validation_errors.append(valid_error)\n",
    "        accu_score = accuracy_score(y_test, y_pred)\n",
    "        names.append(name)\n",
    "        print(name + \": \" + str(accu_score))\n",
    "\n",
    "    # plot\n",
    "    print (\"=== Error Plot ===\")\n",
    "    ax = plt.subplot(1, 2, subplot)\n",
    "    index = np.arange(n_groups)\n",
    "    bar_width = 0.2\n",
    "    opacity = 0.8\n",
    "\n",
    "    rects1 = plt.bar(index, training_errors, bar_width,\n",
    "                 alpha=opacity,\n",
    "                 color='b',\n",
    "                 label='Training Error')\n",
    "\n",
    "    rects2 = plt.bar(index + bar_width, validation_errors, bar_width,\n",
    "                 alpha=opacity,\n",
    "                 color='r',\n",
    "                 label='Validation Error')\n",
    "\n",
    "    #labels\n",
    "    for i, v in enumerate(validation_errors):\n",
    "        ax.text(index[i]+.10, v+.003, str(round(v,2)), color='red', fontweight='bold')\n",
    "    for i, v in enumerate(training_errors):\n",
    "        ax.text(index[i]-.25, v+.003, str(round(v,2)), color='blue', fontweight='bold')\n",
    "\n",
    "    plt.xlabel('Model')\n",
    "    plt.ylabel('Error')\n",
    "    plt.ylim(0,1)\n",
    "    plt.title(title)\n",
    "    plt.xticks(index + bar_width, names)\n",
    "    plt.legend()\n",
    "\n",
    "    return models\n",
    "    #plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of samples: 856\n",
      "=== Accuracy ===\n",
      "LR: 0.5\n",
      "LDA: 0.5\n",
      "KNN: 0.406976744186\n",
      "CART: 0.476744186047\n",
      "NB: 0.5\n",
      "SVM: 0.523255813953\n",
      "RF: 0.46511627907\n",
      "XGBoost: 0.546511627907\n",
      "=== Error Plot ===\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAANkAAAEWCAYAAADrdzKjAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x26de941b9e8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "companies = ['AMZN']#['AMZN', 'FB', 'TSLA', 'GE', 'GS']\n",
    "for company in companies:\n",
    "    # Load data\n",
    "    newsData = pd.read_csv(\"News/sentiment_\" + company + \".csv\", encoding = \"ISO-8859-1\")\n",
    "    stockData = pd.read_csv(\"Prices/label_\" + company + \".csv\")\n",
    "    newsData = newsData.rename(columns={\"trading_date\":\"date\"}) # rename column\n",
    "    \n",
    "    # Merge data frames\n",
    "    merged_df = newsData[['date', 'compound','neg','neu','pos']].merge(stockData[['date','label']], how='inner', on='date', left_index=True)\n",
    "    \n",
    "    # Prepare samples and labels\n",
    "    x = merged_df.loc[:,'compound':'pos']\n",
    "    y = merged_df.loc[:,'label']\n",
    "    \n",
    "    print (\"number of samples: \" + str(len(x)))\n",
    "    \n",
    "    # Train, test and plot\n",
    "    trainAndValidate(x, y, company, 2)\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = merged_df.loc[:,'compound':'pos']\n",
    "y = merged_df.loc[:,'label']\n",
    "\n",
    "x = np.array(x)\n",
    "y = np.array(y)\n",
    "\n",
    "# randomize data\n",
    "n = len(x)\n",
    "indices = np.random.choice(n, n, replace=False)\n",
    "x = x[indices]\n",
    "y = y[indices]\n",
    "\n",
    "# split into train, test and validation\n",
    "train_idx = int(n*.8)\n",
    "test_idx = int(n*.9)\n",
    "\n",
    "x_train = x[:train_idx,:]\n",
    "y_train = y[:train_idx]\n",
    "\n",
    "x_test = x[train_idx:test_idx,:]\n",
    "y_test = y[train_idx:test_idx]\n",
    "\n",
    "x_valid = x[test_idx:,:]\n",
    "y_valid = y[test_idx:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy score:\n",
      "0.523255813953\n",
      "confusion matrix: \n",
      "[[ 5 31]\n",
      " [10 40]]\n",
      "classification report: \n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.33      0.14      0.20        36\n",
      "          1       0.56      0.80      0.66        50\n",
      "\n",
      "avg / total       0.47      0.52      0.47        86\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler().fit(x_train)\n",
    "rescaledX = scaler.transform(x_train)\n",
    "model_xgb = XGBClassifier()\n",
    "model_xgb.fit(rescaledX, y_train)\n",
    "# estimate accuracy on validation dataset\n",
    "rescaledValidationX = scaler.transform(x_test)\n",
    "predictions = model_xgb.predict(rescaledValidationX)\n",
    "print(\"accuracy score:\")\n",
    "print(accuracy_score(y_test, predictions))\n",
    "print(\"confusion matrix: \")\n",
    "print(confusion_matrix(y_test, predictions))\n",
    "print(\"classification report: \")\n",
    "print(classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lxmxl\\Anaconda3\\lib\\site-packages\\matplotlib\\__init__.py:1405: UserWarning: \n",
      "This call to matplotlib.use() has no effect because the backend has already\n",
      "been chosen; matplotlib.use() must be called *before* pylab, matplotlib.pyplot,\n",
      "or matplotlib.backends is imported for the first time.\n",
      "\n",
      "  warnings.warn(_use_error_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12]\n",
      "Score is 0.593023255814 at depth of 1 and estimator 150\n",
      "Score is 0.558139534884 at depth of 2 and estimator 150\n",
      "Score is 0.546511627907 at depth of 3 and estimator 150\n",
      "Score is 0.604651162791 at depth of 4 and estimator 150\n",
      "Score is 0.616279069767 at depth of 5 and estimator 150\n",
      "Score is 0.546511627907 at depth of 6 and estimator 150\n",
      "Score is 0.5 at depth of 7 and estimator 150\n",
      "Score is 0.511627906977 at depth of 8 and estimator 150\n",
      "Score is 0.523255813953 at depth of 9 and estimator 150\n",
      "Score is 0.511627906977 at depth of 10 and estimator 150\n",
      "Score is 0.523255813953 at depth of 11 and estimator 150\n",
      "Score is 0.488372093023 at depth of 12 and estimator 150\n",
      "Score is 0.593023255814 at depth of 1 and estimator 200\n",
      "Score is 0.558139534884 at depth of 2 and estimator 200\n",
      "Score is 0.53488372093 at depth of 3 and estimator 200\n",
      "Score is 0.581395348837 at depth of 4 and estimator 200\n",
      "Score is 0.546511627907 at depth of 5 and estimator 200\n",
      "Score is 0.53488372093 at depth of 6 and estimator 200\n",
      "Score is 0.476744186047 at depth of 7 and estimator 200\n",
      "Score is 0.5 at depth of 8 and estimator 200\n",
      "Score is 0.523255813953 at depth of 9 and estimator 200\n",
      "Score is 0.511627906977 at depth of 10 and estimator 200\n",
      "Score is 0.511627906977 at depth of 11 and estimator 200\n",
      "Score is 0.5 at depth of 12 and estimator 200\n",
      "Score is 0.616279069767 at depth of 1 and estimator 250\n",
      "Score is 0.56976744186 at depth of 2 and estimator 250\n",
      "Score is 0.53488372093 at depth of 3 and estimator 250\n",
      "Score is 0.56976744186 at depth of 4 and estimator 250\n",
      "Score is 0.546511627907 at depth of 5 and estimator 250\n",
      "Score is 0.546511627907 at depth of 6 and estimator 250\n",
      "Score is 0.476744186047 at depth of 7 and estimator 250\n",
      "Score is 0.511627906977 at depth of 8 and estimator 250\n",
      "Score is 0.488372093023 at depth of 9 and estimator 250\n",
      "Score is 0.511627906977 at depth of 10 and estimator 250\n",
      "Score is 0.511627906977 at depth of 11 and estimator 250\n",
      "Score is 0.5 at depth of 12 and estimator 250\n",
      "Score is 0.581395348837 at depth of 1 and estimator 450\n",
      "Score is 0.593023255814 at depth of 2 and estimator 450\n",
      "Score is 0.53488372093 at depth of 3 and estimator 450\n",
      "Score is 0.546511627907 at depth of 4 and estimator 450\n",
      "Score is 0.53488372093 at depth of 5 and estimator 450\n",
      "Score is 0.5 at depth of 6 and estimator 450\n",
      "Score is 0.453488372093 at depth of 7 and estimator 450\n",
      "Score is 0.5 at depth of 8 and estimator 450\n",
      "Score is 0.488372093023 at depth of 9 and estimator 450\n",
      "Score is 0.511627906977 at depth of 10 and estimator 450\n",
      "Score is 0.488372093023 at depth of 11 and estimator 450\n",
      "Score is 0.488372093023 at depth of 12 and estimator 450\n",
      "Score is 0.581395348837 at depth of 1 and estimator 500\n",
      "Score is 0.616279069767 at depth of 2 and estimator 500\n",
      "Score is 0.523255813953 at depth of 3 and estimator 500\n",
      "Score is 0.523255813953 at depth of 4 and estimator 500\n",
      "Score is 0.511627906977 at depth of 5 and estimator 500\n",
      "Score is 0.5 at depth of 6 and estimator 500\n",
      "Score is 0.488372093023 at depth of 7 and estimator 500\n",
      "Score is 0.5 at depth of 8 and estimator 500\n",
      "Score is 0.488372093023 at depth of 9 and estimator 500\n",
      "Score is 0.511627906977 at depth of 10 and estimator 500\n",
      "Score is 0.5 at depth of 11 and estimator 500\n",
      "Score is 0.488372093023 at depth of 12 and estimator 500\n",
      "Score is 0.56976744186 at depth of 1 and estimator 550\n",
      "Score is 0.604651162791 at depth of 2 and estimator 550\n",
      "Score is 0.546511627907 at depth of 3 and estimator 550\n",
      "Score is 0.523255813953 at depth of 4 and estimator 550\n",
      "Score is 0.511627906977 at depth of 5 and estimator 550\n",
      "Score is 0.488372093023 at depth of 6 and estimator 550\n",
      "Score is 0.476744186047 at depth of 7 and estimator 550\n",
      "Score is 0.476744186047 at depth of 8 and estimator 550\n",
      "Score is 0.5 at depth of 9 and estimator 550\n",
      "Score is 0.511627906977 at depth of 10 and estimator 550\n",
      "Score is 0.5 at depth of 11 and estimator 550\n",
      "Score is 0.488372093023 at depth of 12 and estimator 550\n",
      "Score is 0.581395348837 at depth of 1 and estimator 1000\n",
      "Score is 0.581395348837 at depth of 2 and estimator 1000\n",
      "Score is 0.5 at depth of 3 and estimator 1000\n",
      "Score is 0.511627906977 at depth of 4 and estimator 1000\n",
      "Score is 0.5 at depth of 5 and estimator 1000\n",
      "Score is 0.488372093023 at depth of 6 and estimator 1000\n",
      "Score is 0.5 at depth of 7 and estimator 1000\n",
      "Score is 0.488372093023 at depth of 8 and estimator 1000\n",
      "Score is 0.511627906977 at depth of 9 and estimator 1000\n",
      "Score is 0.511627906977 at depth of 10 and estimator 1000\n",
      "Score is 0.5 at depth of 11 and estimator 1000\n",
      "Score is 0.488372093023 at depth of 12 and estimator 1000\n",
      "Best score is 0.616279069767 at depth of 5 and estimator of 150\n"
     ]
    }
   ],
   "source": [
    "# XGBoost on Stock Price dataset, Tune n_estimators and max_depth\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import matplotlib\n",
    "\n",
    "matplotlib.use('Agg')\n",
    "model = XGBClassifier()\n",
    "n_estimators = [150, 200, 250, 450, 500, 550, 1000]\n",
    "max_depth = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12]\n",
    "print(max_depth)\n",
    "best_depth = 0\n",
    "best_estimator = 0\n",
    "max_score = 0\n",
    "for n in n_estimators:\n",
    "    for md in max_depth:\n",
    "        model = XGBClassifier(n_estimators=n, max_depth=md)\n",
    "        model.fit(x_train, y_train)\n",
    "        y_pred = model.predict(x_test)\n",
    "        score = accuracy_score(y_test, y_pred)\n",
    "        if score > max_score:\n",
    "            max_score = score\n",
    "            best_depth = md\n",
    "            best_estimator = n\n",
    "        print(\"Score is \" + str(score) + \" at depth of \" + str(md) + \" and estimator \" + str(n))\n",
    "print(\"Best score is \" + str(max_score) + \" at depth of \" + str(best_depth) + \" and estimator of \" + str(best_estimator))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.2831004, 0.25357574, 0.23341987, 0.22990407]\n",
      "['neg', 'compound', 'neu', 'date']\n"
     ]
    }
   ],
   "source": [
    "features = merged_df.drop(['label'],axis=1).columns.values\n",
    "\n",
    "x, y = (list(x) for x in zip(*sorted(zip(model_xgb.feature_importances_, features), \n",
    "                                                            reverse = True)))\n",
    "print (x)\n",
    "print (y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = merged_df.loc[:,['neg', 'compound', 'neu', 'date']]\n",
    "Xi_train, Xi_test = X.loc[0:train_size, :], X.loc[train_size: len(X.index), :]\n",
    "clf = XGBClassifier(n_estimators=500, max_depth=3)\n",
    "clf.fit(Xi_train, y_train)\n",
    "yi_pred = clf.predict(Xi_test)\n",
    "score = accuracy_score(y_test, yi_pred)\n",
    "print(\"Score is \"+ str(score))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
